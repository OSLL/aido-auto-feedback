False: Incorrect solution execution: Stopping the simulator because we are at an invalid pose.
time=1652723366.124845 gym-duckietown 2019.0.0

time=1652723367.248559 Registering gym environment id: Duckietown-4way-v0
time=1652723367.2487106 Registering gym environment id: Duckietown-loop_dyn_duckiebots-v0
time=1652723367.2488284 Registering gym environment id: Duckietown-loop_empty-v0
time=1652723367.248967 Registering gym environment id: Duckietown-loop_obstacles-v0
time=1652723367.2491047 Registering gym environment id: Duckietown-loop_pedestrians-v0
time=1652723367.249199 Registering gym environment id: Duckietown-small_loop-v0
time=1652723367.249277 Registering gym environment id: Duckietown-small_loop_cw-v0
time=1652723367.249355 Registering gym environment id: Duckietown-straight_road-v0
time=1652723367.2494404 Registering gym environment id: Duckietown-straight_road_10_tiles_no_start_tile-v0
time=1652723367.2495232 Registering gym environment id: Duckietown-straight_road_no_start_tile-v0
time=1652723367.249603 Registering gym environment id: Duckietown-straight_road_trafficlight-v0
time=1652723367.2496774 Registering gym environment id: Duckietown-straight_road_with_side_floor-v0
time=1652723367.2497609 Registering gym environment id: Duckietown-udem1-v0
time=1652723367.2498434 Registering gym environment id: Duckietown-zigzag_dists-v0
time=1652723370.1656294 Falling back to non-multisampled frame buffer
time=1652723370.195144 Falling back to non-multisampled frame buffer
time=1652723370.1996477 loading map file "/home/appuser/aido-auto/gym-duckietown/gym_duckietown/maps/straight_road.yaml"
time=1652723370.214116 loading mesh "duckiebot.obj"
time=1652723370.2218895 loading materials from "/home/appuser/aido-auto/gym-duckietown/gym_duckietown/meshes/duckiebot.mtl"
time=1652723370.633461 loading texture "straight_1.png"
time=1652723370.6923604 road_tile_size=0.585
time=1652723370.6929057 Starting at [0.2925  0.      0.43875] 0
time=1652723370.6932256 Pos: [0.2925  0.      0.43875] angle 0
time=1652723371.0437078 using DuckietownEnv
/usr/local/lib/python3.6/dist-packages/gym/spaces/box.py:74: UserWarning: [33mWARN: Box bound precision lowered by casting to float32[0m
  "Box bound precision lowered by casting to {}".format(self.dtype)
time=1652723371.0461378 loading mesh "duckie.obj"
time=1652723371.096144 loading texture "duckie.png"
time=1652723371.8026364 Pos: [0.2925  0.      0.43875] angle 0
time=1652723372.1611538 Pos: [0.3325  0.      0.43875] angle 0
time=1652723372.2457962 Pos: [0.3725  0.      0.43875] angle 0
time=1652723372.3203878 Pos: [0.4125  0.      0.43875] angle 0
time=1652723372.3943152 Pos: [0.4525  0.      0.43875] angle 0
time=1652723372.4686987 Pos: [0.4925  0.      0.43875] angle 0
time=1652723372.5413904 Pos: [0.5325  0.      0.43875] angle 0
time=1652723372.6151261 Pos: [0.5725  0.      0.43875] angle 0
time=1652723372.6923091 Pos: [0.6125  0.      0.43875] angle 0
time=1652723372.7691212 Pos: [0.6525  0.      0.43875] angle 0
time=1652723372.8408906 Pos: [0.6925  0.      0.43875] angle 0
time=1652723372.9125085 Pos: [0.7325  0.      0.43875] angle 0
time=1652723372.9841323 Pos: [0.7725  0.      0.43875] angle 0
time=1652723373.0594084 Pos: [0.8125  0.      0.43875] angle 0
time=1652723373.1341414 Pos: [0.8525  0.      0.43875] angle 0
time=1652723373.2091863 Pos: [0.8925  0.      0.43875] angle 0
time=1652723373.2848086 Pos: [0.9325  0.      0.43875] angle 0
time=1652723373.3683033 Pos: [0.9725  0.      0.43875] angle 0
time=1652723373.4492967 Pos: [1.0125  0.      0.43875] angle 0
time=1652723373.5314772 Pos: [1.0525  0.      0.43875] angle 0
time=1652723373.6291344 Pos: [1.0925  0.      0.43875] angle 0
time=1652723373.7193282 Pos: [1.1325  0.      0.43875] angle 0
time=1652723373.8197684 Pos: [1.1725  0.      0.43875] angle 0
time=1652723373.8985586 Pos: [1.2125  0.      0.43875] angle 0
time=1652723373.9773781 Pos: [1.2525  0.      0.43875] angle 0
time=1652723374.0658042 Pos: [1.2925  0.      0.43875] angle 0
time=1652723374.1676931 Pos: [1.3325  0.      0.43875] angle 0
time=1652723374.259338 Pos: [1.3725  0.      0.43875] angle 0
time=1652723374.3395581 Pos: [1.4125  0.      0.43875] angle 0
time=1652723374.4221745 Pos: [1.4525  0.      0.43875] angle 0
time=1652723374.5009093 Pos: [1.4925  0.      0.43875] angle 0
time=1652723374.5887427 Pos: [1.5325  0.      0.43875] angle 0
time=1652723374.666626 Pos: [1.5725  0.      0.43875] angle 0
time=1652723374.748766 Pos: [1.6125  0.      0.43875] angle 0
time=1652723374.83132 Pos: [1.6525  0.      0.43875] angle 0
time=1652723374.9077196 Pos: [1.6925  0.      0.43875] angle 0
time=1652723374.9840767 Pos: [1.7325  0.      0.43875] angle 0
env.road_tile_size = 0.585
reward: 0.9074999999999995
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9074999999999995
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9074999999999995
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9074999999999995
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9074999999999995
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9074999999999995
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000016
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000005
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000011
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000005
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000005
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000016
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000011
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000011
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000011
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000011
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000016
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9074999999999978
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000011
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000016
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000016
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000011
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000005
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000005
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000016
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000011
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000011
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000011
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000011
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000016
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000011
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000011
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000011
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000011
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000011
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000016
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}time=1652723375.0768905 Pos: [1.7725  0.      0.43875] angle 0
time=1652723375.1568704 Pos: [1.8125  0.      0.43875] angle 0
time=1652723375.247947 Pos: [1.8525  0.      0.43875] angle 0
time=1652723375.3354795 Pos: [1.8925  0.      0.43875] angle 0
time=1652723375.4140625 Pos: [1.9325  0.      0.43875] angle 0
time=1652723375.5058727 Pos: [1.9725  0.      0.43875] angle 0
time=1652723375.600629 Pos: [2.0125  0.      0.43875] angle 0
time=1652723375.6903756 Pos: [2.0525  0.      0.43875] angle 0
time=1652723375.7810907 Pos: [2.0925  0.      0.43875] angle 0
time=1652723375.871523 Pos: [2.1325  0.      0.43875] angle 0
time=1652723375.9887917 Pos: [2.1725  0.      0.43875] angle 0
time=1652723376.0977087 Pos: [2.2125  0.      0.43875] angle 0
time=1652723376.199044 Pos: [2.2525  0.      0.43875] angle 0
time=1652723376.3041515 Pos: [2.2925  0.      0.43875] angle 0
time=1652723376.4096384 Pos: [2.3325  0.      0.43875] angle 0
time=1652723376.5067961 Pos: [2.3725  0.      0.43875] angle 0
time=1652723376.5997925 Pos: [2.4125  0.      0.43875] angle 0
time=1652723376.6861258 Invalid pose. Collision free: False On drivable area: True
time=1652723376.6864133 safety_factor: 1.0
time=1652723376.686895 pos: [2.4285  0.      0.43875]
time=1652723376.6872916 l_pos: [2.4285  0.      0.36375]
time=1652723376.6876862 r_pos: [2.4285  0.      0.51375]
time=1652723376.6880844 f_pos: [2.5185  0.      0.43875]
time=1652723376.6881928 Stopping the simulator because we are at an invalid pose.
time=1652723376.6885364 Pos: [2.4525  0.      0.43875] angle 0

reward: 0.9075000000000005
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000005
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000005
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000011
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000011
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000011
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000011
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000011
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000011
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000011
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000011
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000011
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000016
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: 0.9075000000000016
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: -0.5273399366956054
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: -2.126515211442645
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
reward: -3.725134080167288
done: False
info: {'Simulator': {'action': [1.0, 1.0], 'msg': ''}, 'DuckietownEnv': {'k': 27.0, 'gain': 1.0, 'train': 0.0, 'radius': 0.0318, 'omega_r': 31.446540880503143, 'omega_l': 31.446540880503143}}
total reward =  38.70351077169449
False: Incorrect solution execution: Stopping the simulator because we are at an invalid pose.
